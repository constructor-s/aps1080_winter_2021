{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhPBFrDZpLawLq5FJEOudc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/constructor-s/aps1080_winter_2021/blob/main/E1/E1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcvdkKS8n7Bl"
      },
      "source": [
        "# Exercise I: Introductory Lectures \r\n",
        "## A. Read Chapter 3 and do the following exercises: 3.7-3.9, 3.12, 3.18, 3.19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HstDan5Doa3z"
      },
      "source": [
        "### 3.7\r\n",
        "\r\n",
        "Noâ€”The agent initially does not have the knowledge of what actions to take to escape the maze. In this situation, the agenent has a constant reward of zero as long as the maze is not escpated. There is no difference learned about different states by the agent. Instead a negative reward needs to be apply when the maze is not escaped to encourage escaping the maze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSXetAO3obIY"
      },
      "source": [
        "### 3.8\r\n",
        "\r\n",
        "Based on equation 3.8:\r\n",
        "\r\n",
        "$$ \\begin{align*}\r\n",
        "G_5 &= 0 \\\\\r\n",
        "G_4 &= R_5 + \\gamma G_5 = 2 \\\\\r\n",
        "G_3 &= R_4 + \\gamma G_4 = 4 \\\\\r\n",
        "G_2 &= R_3 + \\gamma G_3 = 8 \\\\\r\n",
        "G_1 &= R_2 + \\gamma G_2 = 6 \\\\\r\n",
        "G_0 &= R_1 + \\gamma G_1 = 2 \r\n",
        "\\end{align*}$$\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJD93SyEobKm"
      },
      "source": [
        "### 3.9\r\n",
        "\r\n",
        "$$ \r\n",
        "\\begin{align*}\r\n",
        "G_1 &\\doteq \\sum_{k=0}^\\infty \\gamma^k R_{1+k+1} \\\\\r\n",
        "&= \\sum_{k=0}^\\infty 0.9^k 2 \\\\\r\n",
        "&= 10\r\n",
        "\\\\\r\n",
        "\\\\\r\n",
        "G_0 &= R_1 + \\gamma G_1 = 2 + 0.9\\times10 = 11 \r\n",
        "\\end{align*}\r\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlMXw31xobNL"
      },
      "source": [
        "### 3.12\r\n",
        "\r\n",
        "<!-- v_\\pi(q_\\pi,\\pi) \r\n",
        "&= \\mathbb{E}_{(s|q_\\pi,\\pi)}\r\n",
        "\\left[ v_\\pi(s) \\right]\r\n",
        "\\\\ -->\r\n",
        "\r\n",
        "$$ \\begin{align*}\r\n",
        "v_{\\pi}(s) &\\doteq \\mathbb{E}_{\\pi}\r\n",
        "\\left[ G_t | S_t=s \\right]\r\n",
        "\\\\\r\n",
        "&= \\mathbb{E}_{\\pi}\r\n",
        "\\left[ q_{\\pi} (s,a) | S_t=s \\right]\r\n",
        "\\\\\r\n",
        "&= \\sum_{a\\in \\mathcal{A}} \\left[ \\pi(a|s) q_{\\pi} (s,a) \\right]\r\n",
        "\\end{align*} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6uVosP3obPj"
      },
      "source": [
        "### 3.18\r\n",
        "\r\n",
        "$$ \\begin{align*}\r\n",
        "v_{\\pi}(s) &= \\mathbb{E}_{\\pi}\r\n",
        "\\left[ q_{\\pi}(s,a) | S_t=s \\right]\r\n",
        "\\\\\r\n",
        "&= \\sum_{a\\in \\mathcal{A}} \\left[ \\pi(a|s) q_{\\pi} (s,a) \\right]\r\n",
        "\\end{align*} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n_p4i88obRz"
      },
      "source": [
        "### 3.19\r\n",
        "\r\n",
        "$$ \\begin{align*}\r\n",
        "q_{\\pi}(s,a) &= \\mathbb{E}_{p(s',r|s,a)}\\left[\r\n",
        "r+v_{\\pi}(s')\r\n",
        "| S_t=s,A_t=a\r\n",
        "\\right]\r\n",
        "\\\\\r\n",
        "&= \\sum_{s'\\in\\mathcal{S}}\\sum_{r\\in\\mathcal{R}}\\left[\r\n",
        "    p(s',r|s,a)(r+v_{\\pi}(s'))\r\n",
        "\\right]\r\n",
        "\\end{align*} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inj1X63C7y5i"
      },
      "source": [
        "## B. Practical\r\n",
        "### 1. Anatomy\r\n",
        "\r\n",
        "Read the code and observe how the concepts of the course thus far relate to it. Comment on these correspondences. What does an RL agent solve? What should a RL agent have inside of it? Do you observe these in the program?\r\n",
        "\r\n",
        "\r\n",
        "### 2. Instrumentation and Play"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuiVuh5l8C69",
        "outputId": "5910b98d-abe6-45e8-cc28-3b7cdf276a07"
      },
      "source": [
        "#######################################################################\r\n",
        "# Copyright (C)                                                       #\r\n",
        "# 2016 - 2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)           #\r\n",
        "# 2016 Jan Hakenberg(jan.hakenberg@gmail.com)                         #\r\n",
        "# 2016 Tian Jun(tianjun.cpp@gmail.com)                                #\r\n",
        "# 2016 Kenta Shimada(hyperkentakun@gmail.com)                         #\r\n",
        "# Permission given to modify the code as long as you keep this        #\r\n",
        "# declaration at the top                                              #\r\n",
        "#######################################################################\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "\r\n",
        "BOARD_ROWS = 3\r\n",
        "BOARD_COLS = 3\r\n",
        "BOARD_SIZE = BOARD_ROWS * BOARD_COLS\r\n",
        "\r\n",
        "\r\n",
        "class State:\r\n",
        "    def __init__(self):\r\n",
        "        # the board is represented by an n * n array,\r\n",
        "        # 1 represents a chessman of the player who moves first,\r\n",
        "        # -1 represents a chessman of another player\r\n",
        "        # 0 represents an empty position\r\n",
        "        self.data = np.zeros((BOARD_ROWS, BOARD_COLS))\r\n",
        "        self.winner = None\r\n",
        "        self.hash_val = None\r\n",
        "        self.end = None\r\n",
        "\r\n",
        "    # compute the hash value for one state, it's unique\r\n",
        "    def hash(self):\r\n",
        "        if self.hash_val is None:\r\n",
        "            self.hash_val = 0\r\n",
        "            for i in np.nditer(self.data):\r\n",
        "                self.hash_val = self.hash_val * 3 + i + 1\r\n",
        "        return self.hash_val\r\n",
        "\r\n",
        "    # check whether a player has won the game, or it's a tie\r\n",
        "    def is_end(self):\r\n",
        "        if self.end is not None:\r\n",
        "            return self.end\r\n",
        "        results = []\r\n",
        "        # check row\r\n",
        "        for i in range(BOARD_ROWS):\r\n",
        "            results.append(np.sum(self.data[i, :]))\r\n",
        "        # check columns\r\n",
        "        for i in range(BOARD_COLS):\r\n",
        "            results.append(np.sum(self.data[:, i]))\r\n",
        "\r\n",
        "        # check diagonals\r\n",
        "        trace = 0\r\n",
        "        reverse_trace = 0\r\n",
        "        for i in range(BOARD_ROWS):\r\n",
        "            trace += self.data[i, i]\r\n",
        "            reverse_trace += self.data[i, BOARD_ROWS - 1 - i]\r\n",
        "        results.append(trace)\r\n",
        "        results.append(reverse_trace)\r\n",
        "\r\n",
        "        for result in results:\r\n",
        "            if result == 3:\r\n",
        "                self.winner = 1\r\n",
        "                self.end = True\r\n",
        "                return self.end\r\n",
        "            if result == -3:\r\n",
        "                self.winner = -1\r\n",
        "                self.end = True\r\n",
        "                return self.end\r\n",
        "\r\n",
        "        # whether it's a tie\r\n",
        "        sum_values = np.sum(np.abs(self.data))\r\n",
        "        if sum_values == BOARD_SIZE:\r\n",
        "            self.winner = 0\r\n",
        "            self.end = True\r\n",
        "            return self.end\r\n",
        "\r\n",
        "        # game is still going on\r\n",
        "        self.end = False\r\n",
        "        return self.end\r\n",
        "\r\n",
        "    # @symbol: 1 or -1\r\n",
        "    # put chessman symbol in position (i, j)\r\n",
        "    def next_state(self, i, j, symbol):\r\n",
        "        new_state = State()\r\n",
        "        new_state.data = np.copy(self.data)\r\n",
        "        new_state.data[i, j] = symbol\r\n",
        "        return new_state\r\n",
        "\r\n",
        "    # print the board\r\n",
        "    def print_state(self):\r\n",
        "        for i in range(BOARD_ROWS):\r\n",
        "            print('-------------')\r\n",
        "            out = '| '\r\n",
        "            for j in range(BOARD_COLS):\r\n",
        "                if self.data[i, j] == 1:\r\n",
        "                    token = '*'\r\n",
        "                elif self.data[i, j] == -1:\r\n",
        "                    token = 'x'\r\n",
        "                else:\r\n",
        "                    token = '0'\r\n",
        "                out += token + ' | '\r\n",
        "            print(out)\r\n",
        "        print('-------------')\r\n",
        "\r\n",
        "\r\n",
        "def get_all_states_impl(current_state, current_symbol, all_states):\r\n",
        "    for i in range(BOARD_ROWS):\r\n",
        "        for j in range(BOARD_COLS):\r\n",
        "            if current_state.data[i][j] == 0:\r\n",
        "                new_state = current_state.next_state(i, j, current_symbol)\r\n",
        "                new_hash = new_state.hash()\r\n",
        "                if new_hash not in all_states:\r\n",
        "                    is_end = new_state.is_end()\r\n",
        "                    all_states[new_hash] = (new_state, is_end)\r\n",
        "                    if not is_end:\r\n",
        "                        get_all_states_impl(new_state, -current_symbol, all_states)\r\n",
        "\r\n",
        "\r\n",
        "def get_all_states():\r\n",
        "    current_symbol = 1\r\n",
        "    current_state = State()\r\n",
        "    all_states = dict()\r\n",
        "    all_states[current_state.hash()] = (current_state, current_state.is_end())\r\n",
        "    get_all_states_impl(current_state, current_symbol, all_states)\r\n",
        "    return all_states\r\n",
        "\r\n",
        "\r\n",
        "# all possible board configurations\r\n",
        "all_states = get_all_states()\r\n",
        "\r\n",
        "\r\n",
        "class Judger:\r\n",
        "    # @player1: the player who will move first, its chessman will be 1\r\n",
        "    # @player2: another player with a chessman -1\r\n",
        "    def __init__(self, player1, player2):\r\n",
        "        self.p1 = player1\r\n",
        "        self.p2 = player2\r\n",
        "        self.current_player = None\r\n",
        "        self.p1_symbol = 1\r\n",
        "        self.p2_symbol = -1\r\n",
        "        self.p1.set_symbol(self.p1_symbol)\r\n",
        "        self.p2.set_symbol(self.p2_symbol)\r\n",
        "        self.current_state = State()\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.p1.reset()\r\n",
        "        self.p2.reset()\r\n",
        "\r\n",
        "    def alternate(self):\r\n",
        "        while True:\r\n",
        "            yield self.p1\r\n",
        "            yield self.p2\r\n",
        "\r\n",
        "    # @print_state: if True, print each board during the game\r\n",
        "    def play(self, print_state=False):\r\n",
        "        alternator = self.alternate()\r\n",
        "        self.reset()\r\n",
        "        current_state = State()\r\n",
        "        self.p1.set_state(current_state)\r\n",
        "        self.p2.set_state(current_state)\r\n",
        "        if print_state:\r\n",
        "            current_state.print_state()\r\n",
        "        while True:\r\n",
        "            player = next(alternator)\r\n",
        "            i, j, symbol = player.act()\r\n",
        "            next_state_hash = current_state.next_state(i, j, symbol).hash()\r\n",
        "            current_state, is_end = all_states[next_state_hash]\r\n",
        "            self.p1.set_state(current_state)\r\n",
        "            self.p2.set_state(current_state)\r\n",
        "            if print_state:\r\n",
        "                current_state.print_state()\r\n",
        "            if is_end:\r\n",
        "                return current_state.winner\r\n",
        "\r\n",
        "\r\n",
        "# AI player\r\n",
        "class Player:\r\n",
        "    # @step_size: the step size to update estimations\r\n",
        "    # @epsilon: the probability to explore\r\n",
        "    def __init__(self, step_size=0.1, epsilon=0.1):\r\n",
        "        self.estimations = dict()\r\n",
        "        self.step_size = step_size\r\n",
        "        self.epsilon = epsilon\r\n",
        "        self.states = []\r\n",
        "        self.greedy = []\r\n",
        "        self.symbol = 0\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.states = []\r\n",
        "        self.greedy = []\r\n",
        "\r\n",
        "    def set_state(self, state):\r\n",
        "        self.states.append(state)\r\n",
        "        self.greedy.append(True)\r\n",
        "\r\n",
        "    def set_symbol(self, symbol):\r\n",
        "        self.symbol = symbol\r\n",
        "        for hash_val in all_states:\r\n",
        "            state, is_end = all_states[hash_val]\r\n",
        "            if is_end:\r\n",
        "                if state.winner == self.symbol:\r\n",
        "                    self.estimations[hash_val] = 1.0\r\n",
        "                elif state.winner == 0:\r\n",
        "                    # we need to distinguish between a tie and a lose\r\n",
        "                    self.estimations[hash_val] = 0.5\r\n",
        "                else:\r\n",
        "                    self.estimations[hash_val] = 0\r\n",
        "            else:\r\n",
        "                self.estimations[hash_val] = 0.5\r\n",
        "\r\n",
        "    # update value estimation\r\n",
        "    def backup(self):\r\n",
        "        states = [state.hash() for state in self.states]\r\n",
        "\r\n",
        "        for i in reversed(range(len(states) - 1)):\r\n",
        "            state = states[i]\r\n",
        "            td_error = self.greedy[i] * (\r\n",
        "                self.estimations[states[i + 1]] - self.estimations[state]\r\n",
        "            )\r\n",
        "            self.estimations[state] += self.step_size * td_error\r\n",
        "\r\n",
        "    # choose an action based on the state\r\n",
        "    def act(self):\r\n",
        "        state = self.states[-1]\r\n",
        "        next_states = []\r\n",
        "        next_positions = []\r\n",
        "        for i in range(BOARD_ROWS):\r\n",
        "            for j in range(BOARD_COLS):\r\n",
        "                if state.data[i, j] == 0:\r\n",
        "                    next_positions.append([i, j])\r\n",
        "                    next_states.append(state.next_state(\r\n",
        "                        i, j, self.symbol).hash())\r\n",
        "\r\n",
        "        if np.random.rand() < self.epsilon:\r\n",
        "            action = next_positions[np.random.randint(len(next_positions))]\r\n",
        "            action.append(self.symbol)\r\n",
        "            self.greedy[-1] = False\r\n",
        "            return action\r\n",
        "\r\n",
        "        values = []\r\n",
        "        for hash_val, pos in zip(next_states, next_positions):\r\n",
        "            values.append((self.estimations[hash_val], pos))\r\n",
        "        # to select one of the actions of equal value at random due to Python's sort is stable\r\n",
        "        np.random.shuffle(values)\r\n",
        "        values.sort(key=lambda x: x[0], reverse=True)\r\n",
        "        action = values[0][1]\r\n",
        "        action.append(self.symbol)\r\n",
        "        return action\r\n",
        "\r\n",
        "    def save_policy(self):\r\n",
        "        with open('policy_%s.bin' % ('first' if self.symbol == 1 else 'second'), 'wb') as f:\r\n",
        "            pickle.dump(self.estimations, f)\r\n",
        "\r\n",
        "    def load_policy(self):\r\n",
        "        with open('policy_%s.bin' % ('first' if self.symbol == 1 else 'second'), 'rb') as f:\r\n",
        "            self.estimations = pickle.load(f)\r\n",
        "\r\n",
        "\r\n",
        "# human interface\r\n",
        "# input a number to put a chessman\r\n",
        "# | q | w | e |\r\n",
        "# | a | s | d |\r\n",
        "# | z | x | c |\r\n",
        "class HumanPlayer:\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        self.symbol = None\r\n",
        "        self.keys = ['q', 'w', 'e', 'a', 's', 'd', 'z', 'x', 'c']\r\n",
        "        self.state = None\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def set_state(self, state):\r\n",
        "        self.state = state\r\n",
        "\r\n",
        "    def set_symbol(self, symbol):\r\n",
        "        self.symbol = symbol\r\n",
        "\r\n",
        "    def act(self):\r\n",
        "        self.state.print_state()\r\n",
        "        key = input(\"Input your position:\")\r\n",
        "        data = self.keys.index(key)\r\n",
        "        i = data // BOARD_COLS\r\n",
        "        j = data % BOARD_COLS\r\n",
        "        return i, j, self.symbol\r\n",
        "\r\n",
        "\r\n",
        "def train(epochs, print_every_n=500):\r\n",
        "    player1 = Player(epsilon=0.01)\r\n",
        "    player2 = Player(epsilon=0.01)\r\n",
        "    judger = Judger(player1, player2)\r\n",
        "    player1_win = 0.0\r\n",
        "    player2_win = 0.0\r\n",
        "    for i in range(1, epochs + 1):\r\n",
        "        winner = judger.play(print_state=False)\r\n",
        "        if winner == 1:\r\n",
        "            player1_win += 1\r\n",
        "        if winner == -1:\r\n",
        "            player2_win += 1\r\n",
        "        if i % print_every_n == 0:\r\n",
        "            print('Epoch %d, player 1 winrate: %.02f, player 2 winrate: %.02f' % (i, player1_win / i, player2_win / i))\r\n",
        "        player1.backup()\r\n",
        "        player2.backup()\r\n",
        "        judger.reset()\r\n",
        "    player1.save_policy()\r\n",
        "    player2.save_policy()\r\n",
        "\r\n",
        "\r\n",
        "def compete(turns):\r\n",
        "    player1 = Player(epsilon=0)\r\n",
        "    player2 = Player(epsilon=0)\r\n",
        "    judger = Judger(player1, player2)\r\n",
        "    player1.load_policy()\r\n",
        "    player2.load_policy()\r\n",
        "    player1_win = 0.0\r\n",
        "    player2_win = 0.0\r\n",
        "    for _ in range(turns):\r\n",
        "        winner = judger.play()\r\n",
        "        if winner == 1:\r\n",
        "            player1_win += 1\r\n",
        "        if winner == -1:\r\n",
        "            player2_win += 1\r\n",
        "        judger.reset()\r\n",
        "    print('%d turns, player 1 win %.02f, player 2 win %.02f' % (turns, player1_win / turns, player2_win / turns))\r\n",
        "\r\n",
        "\r\n",
        "# The game is a zero sum game. If both players are playing with an optimal strategy, every game will end in a tie.\r\n",
        "# So we test whether the AI can guarantee at least a tie if it goes second.\r\n",
        "def play():\r\n",
        "    while True:\r\n",
        "        player1 = HumanPlayer()\r\n",
        "        player2 = Player(epsilon=0)\r\n",
        "        judger = Judger(player1, player2)\r\n",
        "        player2.load_policy()\r\n",
        "        winner = judger.play()\r\n",
        "        if winner == player2.symbol:\r\n",
        "            print(\"You lose!\")\r\n",
        "        elif winner == player1.symbol:\r\n",
        "            print(\"You win!\")\r\n",
        "        else:\r\n",
        "            print(\"It is a tie!\")\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    train(int(1e5))\r\n",
        "    compete(int(1e3))\r\n",
        "    # play()\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 turns, player 1 win 0.00, player 2 win 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M5RUlBL88pvr",
        "outputId": "8ff2cd20-c27b-4665-9c98-ff51d841d8e0"
      },
      "source": [
        "play()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "Input your position:s\n",
            "-------------\n",
            "| x | 0 | 0 | \n",
            "-------------\n",
            "| 0 | * | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "Input your position:c\n",
            "-------------\n",
            "| x | 0 | x | \n",
            "-------------\n",
            "| 0 | * | 0 | \n",
            "-------------\n",
            "| 0 | 0 | * | \n",
            "-------------\n",
            "Input your position:z\n",
            "You lose!\n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n",
            "| 0 | 0 | 0 | \n",
            "-------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-425fd712de3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-d30ff0d91245>\u001b[0m in \u001b[0;36mplay\u001b[0;34m()\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mjudger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJudger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mplayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjudger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mplayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You lose!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d30ff0d91245>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, print_state)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malternator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mnext_state_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_state_hash\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d30ff0d91245>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input your position:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBOARD_COLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}